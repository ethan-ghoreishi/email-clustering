{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['allen-p/_sent_mail/10.',\n",
       "       \"Message-ID: <15464986.1075855378456.JavaMail.evans@thyme>\\nDate: Fri, 4 May 2001 13:51:00 -0700 (PDT)\\nFrom: phillip.allen@enron.com\\nTo: john.lavorato@enron.com\\nSubject: Re:\\nMime-Version: 1.0\\nContent-Type: text/plain; charset=us-ascii\\nContent-Transfer-Encoding: 7bit\\nX-From: Phillip K Allen\\nX-To: John J Lavorato <John J Lavorato/ENRON@enronXgate@ENRON>\\nX-cc: \\nX-bcc: \\nX-Folder: \\\\Phillip_Allen_Jan2002_1\\\\Allen, Phillip K.\\\\'Sent Mail\\nX-Origin: Allen-P\\nX-FileName: pallen (Non-Privileged).pst\\n\\nTraveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.\\n\\nAs far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.  \\n\\nMy suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time.\\n\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('./input/emails.csv')\n",
    "data.values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_regex = re.compile('([\\[\\(] *)?.*(RE?S?|FWD?|re\\[\\d+\\]?) *([-:;)\\]][ :;\\])-]*|$)|\\]+ *$', flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message-ID: <33076797.1075855687515.JavaMail.evans@thyme>\n",
      "Date: Mon, 16 Oct 2000 06:42:00 -0700 (PDT)\n",
      "From: phillip.allen@enron.com\n",
      "To: buck.buckner@honeywell.com\n",
      "Subject: Re: FW: fixed forward or other Collar floor gas price terms\n",
      "Mime-Version: 1.0\n",
      "Content-Type: text/plain; charset=us-ascii\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-From: Phillip K Allen\n",
      "X-To: \"Buckner, Buck\" <buck.buckner@honeywell.com> @ ENRON\n",
      "X-cc: \n",
      "X-bcc: \n",
      "X-Folder: \\Phillip_Allen_Dec2000\\Notes Folders\\'sent mail\n",
      "X-Origin: Allen-P\n",
      "X-FileName: pallen.nsf\n",
      "\n",
      "Mr. Buckner,\n",
      "\n",
      " For delivered gas behind San Diego, Enron Energy Services is the appropriate \n",
      "Enron entity.  I have forwarded your request to Zarin Imam at EES.  Her phone \n",
      "number is 713-853-7107.  \n",
      "\n",
      "Phillip Allen\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "subject_regex = re.compile('([\\[\\(] *)?.*(RE?S?|FWD?|re\\[\\d+\\]?) *([-:;)\\]][ :;\\])-]*|$)|\\]+ * (.*) $', flags=re.IGNORECASE)\n",
    "print(emails.message[10])\n",
    "a = re.compile('^.*\\b(Subject|Re|FW)\\b.*$')\n",
    "print(re.match(a, emails['message'][10]))\n",
    "# re.search(subject_regex, emails['message'][10]).group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 248912 non-duplicate emails\n",
      "\n",
      "Sample email, unstructured content:\n",
      "\n",
      " ['phillip.allen@enron.com', 'john.lavorato@enron.com', \"Traveling to have a business meeting takes the fun out of the trip.  Especially if you have to prepare a presentation.  I would suggest holding the business plan meetings here then take a trip without any formal business meetings.  I would even try and get some honest opinions on whether a trip is even desired or necessary.  As far as the business meetings, I think it would be more productive to try and stimulate discussions across the different groups about what is working and what is not.  Too often the presenter speaks and the others are quiet just waiting for their turn.   The meetings might be better if held in a round table discussion format.    My suggestion for where to go is Austin.  Play golf and rent a ski boat and jet ski's.  Flying somewhere takes too much time. \"]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def extract_csv_data(file, cols_to_clean = [], exclude = [[]]):\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "    for i, col in enumerate(cols_to_clean):\n",
    "        exclude_pattern = re.compile('|'.join(exclude[i]))\n",
    "        data = data[data[col].str.contains(exclude_pattern) == False]\n",
    "\n",
    "    return data\n",
    "\n",
    "# Input data files are available in the \"./input/\" directory.\n",
    "\n",
    "# emails = extract_csv_data(\n",
    "#     './input/emails.csv',\n",
    "#     ['file'],\n",
    "#     [['notes_inbox', 'discussion_threads']]\n",
    "# )\n",
    "\n",
    "def remove_duplicates(data):\n",
    "    processed = set()\n",
    "    result = []\n",
    "    \n",
    "    from_regex = re.compile(r'From:\\s(\\w)+(\\.)?(\\w)*@(\\w)+.com')\n",
    "    to_regex = re.compile(r'To:\\s(\\w)+(\\.)?(\\w)*@(\\w)+.com')\n",
    "    subject_regex = re.compile('([\\[\\(] *)?.*(RE?S?|FWD?|re\\[\\d+\\]?) *([-:;)\\]][ :;\\])-]*|$)|\\]+ *$', re.IGNORECASE)\n",
    "    pattern = re.compile('X-FileName: .*')\n",
    "    pattern2 = re.compile('X-FileName: .*?  ')\n",
    "\n",
    "    for doc in data:\n",
    "        from_email_address = from_regex.search(doc)\n",
    "        from_email_address = from_email_address.group(0).replace('From: ','',1) if from_email_address is not None else ''\n",
    "        to_email_address = to_regex.search(doc)\n",
    "        to_email_address = to_email_address.group(0).replace('To: ','',1) if to_email_address is not None else ''\n",
    "        subject_line = subject_regex.search(doc)\n",
    "        doc = doc.replace('\\n', ' ')\n",
    "        doc = doc.replace(' .*?nsf', '')\n",
    "        match = pattern.search(doc).group(0)\n",
    "        match = re.sub(pattern2, '', match)\n",
    "\n",
    "        if match not in processed:\n",
    "            processed.add(match)\n",
    "            result.append([from_email_address, to_email_address, match])\n",
    "\n",
    "    return result\n",
    "\n",
    "email_bodies = emails.message.as_matrix()\n",
    "unique_emails = remove_duplicates(email_bodies)\n",
    "\n",
    "print('There are a total of {} non-duplicate emails\\n'.format(len(unique_emails)))\n",
    "print('Sample email, unstructured content:\\n\\n', unique_emails[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 248912 non-duplicate emails\n",
      "\n",
      "Sample email, unstructured content:\n",
      "\n",
      " ['phillip.allen@enron.com', 'cooper.richey@enron.com', \"I tried the new address but I don't have access.  also, what do I need to  enter under domain?\"]\n"
     ]
    }
   ],
   "source": [
    "print('There are a total of {} non-duplicate emails\\n'.format(len(unique_emails)))\n",
    "print('Sample email, unstructured content:\\n\\n', unique_emails[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['traveling', 'business', 'meeting', 'take', 'fun', 'trip', 'especially', 'prepare', 'presentation', 'would', 'suggest', 'holding', 'business', 'plan', 'meeting', 'take', 'trip', 'without', 'formal', 'business', 'meeting', 'would', 'even', 'try', 'get', 'honest', 'opinion', 'whether', 'trip', 'even', 'desired', 'necessary', 'far', 'business', 'meeting', 'think', 'would', 'productive', 'try', 'stimulate', 'discussion', 'across', 'different', 'group', 'working', 'not', 'often', 'presenter', 'speaks', 'others', 'quiet', 'waiting', 'turn', 'meeting', 'might', 'better', 'held', 'round', 'table', 'discussion', 'format', 'suggestion', 'go', 'austin', 'play', 'golf', 'rent', 'ski', 'boat', 'jet', 'ski', 'flying', 'somewhere', 'take', 'much', 'time']\n"
     ]
    }
   ],
   "source": [
    "## Cleaning and Lemmatizing\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "def clean(doc):\n",
    "    words_to_exclude = set(stopwords.words('english'))\n",
    "    exclude = set(string.punctuation)\n",
    "    lemma = WordNetLemmatizer()\n",
    "\n",
    "    word_free = \" \".join([i for i in doc.lower().split() if i not in words_to_exclude])\n",
    "    punc_free = ''.join(ch for ch in word_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "\n",
    "    return normalized\n",
    "\n",
    "def clean_data(data):\n",
    "    return [clean(doc).split(' ') for doc in data]\n",
    "\n",
    "training_set = clean_data(unique_emails[0:200000])\n",
    "testing_set = clean_data(unique_emails[200000:])\n",
    "\n",
    "print(training_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(47483 unique tokens: ['', 'servicesenron', 'olsennaenronenron', 'keiths', '2x']...)\n"
     ]
    }
   ],
   "source": [
    "## Creating a dictionary\n",
    "\n",
    "import gensim\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(training_set)\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.1)\n",
    "\n",
    "print(dictionary)"
   ]
  }
